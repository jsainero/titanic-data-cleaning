---
title: 'PRA2: Limpieza y análisis de datos'
author: "Álvaro López y Jorge Sainero"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  pdf_document: 
    toc: yes
    toc_depth: 2
    number_sections: yes
  html_document:
    toc: yes
    number_sections: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(tinytex.verbose = TRUE)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
```


# Descripción del dataset

El dataset que hemos elegido para realizar esta práctica es el que aperecía como una de las posibles opciones del enunciado ["Titanic: Machine Learning from Disaster"](https://www.kaggle.com/c/titanic).

Este dataset contiene información sobre los pasajeros que iban en el Titanic y es un conjunto de datos importante y relevante a nivel histórico porque contiene información sobre el naufragio que es una de las mayores tragedias marítimas de la historia.

Este dataset pretende responder a qué criterios se siguieron a la hora de salvar las vidas de los pasajeros y la tripulación o si simplemente fue azar. Se determinarán qué variables influyeron más en la supervivencia de los pasajeros.

Para resolver el problema, primero se seleccionarán los datos de interés y se limpiará el conjunto de datos para que los posteriores análisis estén dotados de calidad. Seguidamente se comprobará la normalidad y la homoscedasticidad que ayudarán a entender las variables cuantitativas. Después se harán dos contrastes de hipótesis que adaptan las propiedades de la muestra en la población, una regresión logística y un modelo de _randomForest_, los cuales clasificarán registros no etiquetados en si un pasajero sobrevive o no.


# Selección de los datos de interés

Comenzamos cargando el dataset y viendo la estructura de este.

```{r}
titanic <- read.csv('data/titanic_train_data.csv')
str(titanic)
```

Observamos que el dataset tiene 891 observaciones donde cada observación representa a un pasajero, y hay 12 columnas que informan cada registro.

Las columnas son las siguientes:

|Columna|Descripción|
|-------|-----------|
| PassengerId| Id para identificar el registro. Único para cada fila |
| Survived | Indica si el pasajero sobrevivió o no. 0 = No, 1  = Sí |
| Pclass | Clase del billete. 1 = primera, 2 = segunda, 3 = tercera |
| Name | Nombre del pasajaro |
| Sex | Género del pasajero |
| Age | Edad del pasajero |
| SibSp | Número de hermanos y pareja del pasajero que viajaban en el barco |
| Parch | Número de padres e hijos del pasajero que viajaban en el barco |
| Ticket | Número del ticket |
| Fare | Precio del ticket |
| Cabin | Número de la cabina |
| Embarked | Indica donde embarcó el pasajero. C = Cherbourg, Q = Queenstown, S = Southampton |

## Eliminación de las columnas que no son de interés

En principio la columna *Name* no parece ser de interés, pero como se ve en la estructura y que se repite en todo el dataset, todos los pasajeros tienen un honorífico o título personal, como `Miss.` o `Mr`. A continuación se extrae el título.

```{r echo=FALSE, warning=FALSE, message=FALSE}
if (!require('stringr')) install.packages('stringr'); library('stringr')
```

```{r}
nombre <- titanic$Name

extraccion <- str_extract(nombre, ", [A-Za-z ]*")
extraccion <- substring(extraccion, first=3)

PersonalTitle <- extraccion
table(PersonalTitle)
```

Hay 17 niveles, y solo 4 identifican a más de 10 pasajeros. Los tres títulos más comunes son `Mr` para hombres adultos, `Miss` para mujeres no casadas y `Mrs` para mujeres casadas. Como hay muchos con poca representación y _Sex_ ya identifica a hombres y mujeres, esta nueva variable no se incluye en el dataset.

De las colunmas originales, el *PassengerId* y el *Name* no nos aportan niguna información así que las eliminaremos.

```{r}
titanic <- titanic[,c(2,3,5:12)]
```


Revisamos el resto de los campos para ver si hay alguno más que no vaya a aportar valor al análisis.

```{r}
head(titanic, 5)
```

Observando los campos *Ticket* y *Cabin* parece que van a ser identificadores únicos o casi únicos y que no van a aportar valor al análisis así que decidimos eliminarlos también.

```{r}
titanic <- titanic[,c(1:6,8,10)]
```

## Cambio de tipo de las columnas

Antes de comenzar con la limpieza de los datos, conviene que las columnas sean del tipo correcto. Observando la descripción de las columnas, tenemos cuatro columnas que son de tipo `factor` y no de tipo númerico o string: _Survived_, _Pclass_, _Sex_ y _Embarked_.

```{r}
titanic$Survived <- factor(titanic$Survived, levels = c(0,1), labels = c('No','Yes'))
titanic$Pclass <- factor(titanic$Pclass, levels = c(1,2,3), labels = c('1st','2nd','3rd'))
titanic$Sex <- as.factor(titanic$Sex)
titanic$Embarked <- factor(titanic$Embarked, levels = c('C','Q','S'),
                           labels = c('Cherbourg','Queenstown','Southampton'))
```

Comprobamos que este cambio se ha realizado correctamente.

```{r}
summary(titanic)
```


# Limpieza de datos

## Análisis de nulos, ceros y elementos vacíos

```{r}
colSums(is.na(titanic))
```

Vemos que tenemos 2 registros con la variable _Embarked_ a nulo. Esto no nos debería preocupar demasiado ya que no son demasiados y podríamos tomar la decisión de eliminar estos registros del dataset. En cambio tenemos 177 registros con la variable _Age_ a nulo. En este caso si tenemos que decidir entre imputar los valores o eliminar la variable del análisis. La primera opción es la más viable porque no es factible eliminar casi el 20% de los registros del conjunto.

```{r}
colSums(titanic=="")
colSums(titanic==0)
```

Comprobando también qué valores son vacíos o cero no vemos nada extraño. Observamos que hay un gran número de personas que viajan sin familiares o sin familia (*SibSp* y _Parch_ igual a 0) y que hay 15 pasajeros que viajan gratis (*Fare* igual a 0).

### Tratamiento de valores nulos

Como hemos comentado antes, los registros con las variable _Embarked_ a nula los vamos a eliminar.

```{r}
ind.Embarked <- which(is.na(titanic$Embarked))
titanic <- titanic[-ind.Embarked,]
```


Para imputar los valores de la variable _Age_ hemos optado por el algoritmo KNN (*K-Nearest-Neighbor*), implementado mediante la función _kNN_ del paquete _VIM_. Realiza la media ponderada de los k vecinos más cercanos, en este caso 10.

Antes se grafica el histograma de la edad para ver, después de imputar los valores faltantes, la diferencia en la distribución.

```{r echo=FALSE, fig.height=3, fig.width=5, fig.align='center'}
hist(titanic$Age, main='Density histogram Age', ylab='Density', xlab="Age", ylim=c(0.00, 0.04), breaks=30, freq=FALSE)
```

La mayor densidad se encuentra en el rango de edad entre 20 y 30 años. Hacia la izquierda nos encontramos con un valle para luego aumentar para niños menos de 4 años, pero hacia la derecha tiende a decrecer poco a poco.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
if(!require("VIM")) install.packages("VIM")
library("VIM")
```

Ahora se imputan los valores faltantes de _Age_.
```{r}
titanic$Age <- trunc(kNN(titanic, variable = "Age", k = 10, numFun =  "weightedMean",
                         imp_var = FALSE)$Age)
```

```{r echo=FALSE, fig.height=3, fig.width=5, fig.align='center'}
hist(titanic$Age, main='Density histogram Age', ylab='Density', xlab="Age", ylim=c(0.00,0.05), breaks=30, freq=FALSE)
```

La distribución es aproximadamente la misma. El único aumento considerable es entre 28 y 30 años. Gran parte de los pasajeros de los que no se disponía la edad podían tener esa edad aproximada.

```{r}
summary(titanic$Age)
```

El resumen de la variable modificada es similar al de la variable original. El valor que más cambia es la mediana, pasando de 28 años a 29 años.

Concluimos que esta forma de imputar los valores es mejor que haber colocado a todos los registros el valor de la media o la mediana.


## Detección y tratamiento de outliers

Los _outliers_ o valores extremos son los datos que se encuentran significativamente alejados del resto de datos. Si se tratan de valores razonables se dejarán los registros. De lo contrario, se eliminarán.

```{r echo=FALSE, fig.height=4, fig.width=6}
par(mfrow = c(1, 2))
{boxplot(titanic$Age,main="Box plot age", col="gray", ylab="Age")
boxplot(titanic$Fare,main="Box plot fare", col="gray", ylab="Fare")}
```

Observamos que en el caso de la edad no vemos ningún outlier que sea relevante ya que los que vemos pertenecen a personas que tienen entre 60 y 80 años que son valores razonables aunque sean notablemente superiores a los del resto del conjunto.

En el caso de la variable *Fare* vemos muchos outliers lo que puede ser porque las tarifas cambien en función de donde hayan embarcado los pasajeros por lo que vamos a repetir el dibujo de los boxplots pero para cada uno de los conjuntos.

```{r echo=FALSE, fig.height=4, fig.width=6}
boxplot(Fare ~ Embarked, data = titanic, main="Box plot Fare vs Embarked")
```

Como sucedía con la edad, los outliers no tan alejados de las cajas se consideran razonables, pero vemos dos puntos (que realmente podrían ser dos o más registros) destacados en los casos de `Cherbourg` y `Queenstown` que analizaremos a continuación.

```{r}
max.Cherbourg <- max(boxplot.stats(titanic[titanic$Embarked == 'Cherbourg', 'Fare'])$out)
titanic[titanic$Fare == max.Cherbourg & titanic$Embarked == 'Cherbourg',]

max.Queenstown <- max(boxplot.stats(titanic[titanic$Embarked == 'Queenstown', 'Fare'])$out)
titanic[titanic$Fare == max.Queenstown & titanic$Embarked == 'Queenstown',]
```

Los cinco precios no parecen ser outliers ya que pertenecen a pasajeros con billetes de primera clase que son los más caros. Así que no los eliminaremos del conjunto de datos.

## Guardar nuevo dataset

Después de eliminar las cuatro variables y los dos registros, guardamos el nuevo conjunto de datos csv.

```{r}
write.csv(titanic, "output/titanic_train_data_clean.csv")
```


# Análisis de datos

## Selección de los grupos de datos a analizar

Partiendo de la premisa de que la variable principal de nuestro conjunto de datos es la variable _Survived_, los dos grupos principales que compararemos son supervivientes y no supervivientes a través de las distintas variables.

Primero visualizaremos la variable _Survived_ individualmente y luego generaremos una serie de diagramas de barras y gráficos de cajas para ver la distribución de _Survived_ y su relación con el resto de variables.

```{r echo=FALSE, fig.height=3, fig.width=4, fig.align='center'}
ggplot(data=titanic,aes(x=Survived,fill = Survived))+geom_bar()
```

El grupo con más representación es `No`, correspondiente a los pasajeros que no sobrevivieron. Hay 549 registros de fallecidos y 340 de supervivientes.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
if (!require('gridExtra')) install.packages('gridExtra'); library('gridExtra')
```

Para las variables _SibSp_ y _Parch_ además de los diagramas de barras, optamos por estandarizar cada barra para que tenga la misma altura y muestre las proporciones relativas para apreciar bien todos los grupos.

```{r echo=FALSE}
ggp1 <- ggplot(data=titanic,aes(x=Pclass,fill=Survived))+geom_bar()
ggp2 <- ggplot(data=titanic,aes(x=Sex,fill=Survived))+geom_bar()
ggp3 <- ggplot(data=titanic,aes(x=SibSp,fill=Survived))+geom_bar()
ggp4 <- ggplot(data=titanic,aes(x=SibSp,fill=Survived))+geom_bar(position="fill")+ylab("frequency")
grid.arrange(ggp1, ggp2, ggp3, ggp4, nrow=2, ncol=2)
```

Respecto a los gráficos, cabe destacar que más del doble de pasajeros tienen billetes de tercera clase y el 65% aproximadamente de todos los pasajeros son hombres. Sin embargo, estos dos grupos para sus respectivas variables son quienes menos probabilidad de supervivencia tienen. El número de parejas o hermanos también en barco es mayoritariamente 0, seguido de 1. Hay más probabilidad de sobrevivir acompañado de 1 o 2 personas que de ninguna.

```{r echo=FALSE}
ggp5 <- ggplot(data=titanic,aes(x=Parch,fill=Survived))+geom_bar()
ggp6 <- ggplot(data=titanic,aes(x=Parch,fill=Survived))+geom_bar(position="fill")+ylab("frequency")
ggp7 <- ggplot(data=titanic,aes(x=Embarked,fill=Survived))+geom_bar()+guides(x = guide_axis(n.dodge=2))
grid.arrange(ggp5, ggp6, ggp7, nrow=2, ncol=2)
```
El número de padres e hijos también en el barco aumenta en 0 y 2 respecto a _SibSp_, aunque los que van en este aspecto solos tienen aproximadamente la sobrevivir. El 72% de pasajeros embarcaron en Southampton pero estos tienen un 34% de supervivencia, el menor porcentaje de los tres lugares.


```{r echo=FALSE, fig.height=3, fig.width=7, fig.align='center'}
par(mfrow = c(1, 2))
{boxplot(Age ~ Survived, data = titanic, main="Box plot Survived vs Age",
        col=c('red', 'green'))
  boxplot(Fare ~ Survived, data = titanic, main="Box plot Survived vs Fare",
        col=c('red', 'green'))}
```

Respecto a _Age_, el el 50% del boxplot (caja) de los fallecidos abarca más edades que los supervivientes. Y para _Fare_ ocurre lo contrario. Estos dos diagramas ayudarán a definir si hay homogeneidad en la varianza o no.

De todos las variables comparadas con _Survived_, se usarán aquellas que para la regresión logística y _random forest_ sean útiles. Y para los contrastes de hipótesis se usará _Survived_ con _Fare_ y _Survived_ con _Sex_.

## Comprobación de la normalidad y homogeneidad de la varianza

### Normalidad
El análisis de la normalidad determina si los datos de la muestra se han extraído de una población distribuida normalmente. Dos gráficos con los que es posible comprobar la normalidad son el gráfico Q-Q o cuantil-cuantil y el diagrama de densidad con la curva de distribución normal.

El Q-Q Plot permite identificar la desviación de los datos de la muestra respecto a una población normal. Mediante *qqline* se dibuja una línea recta correspondiente a la distribución normal teórica, y mediante *qqnorm* se dibujan los puntos, que son los datos distribuidos según los cuantiles teóricos. Si los puntos siguen la línea, los datos se distribuyen normalmente.

El diagrama de densidad muestra la distribución de los datos. Se aproximarán a una distribución normal si la densidad es simétrica, centrada en el medio, y disminuye hacia las 2 desviaciones estándar de la media, dentro de las cuales se encuentra aproximadamente el 95% de los datos.

**Variable _Age_**

```{r echo=FALSE, fig.height=3.5, fig.width=7}
par(mfrow = c(1, 2))
{{qqnorm(titanic$Age, main="Normal Q-Q Plot Age")
qqline(titanic$Age)}
{(hist(titanic$Age, main='Density histogram Age', ylab='Density', xlab="Age", freq=FALSE, breaks=20))
lines(density(titanic$Age), col="red", lwd=2)}}
```

En el Q-Q Plot, los datos hacia los extremos se alejan de la recta. El histograma de densidad ya se había comentado anteriormente y se observa la caída suave hacia la derecha pero rápidamente hacia la izquierda, para dejar un pequeño valle.

En base a las representaciones se concluiría que los datos no siguen una distribución normal. No obstante, para comprobarlo se usa el test de Shapiro-Wilk. Asume como hipótesis nula que la población está distribuida normalmente. Se rechazará si el p-valor es inferior al nivel de significancia $\alpha=0.05$.

```{r}
shapiro.test(titanic$Age)
```

Como el p-valor es inferior a 0.05, efectivamente se rechaza la hipótesis nula, afirmano la no normalidad de los datos. 

Por otro lado, como el conjunto de datos es suficientemente grande (879 registros), y por el teorema del límite central (TLC) se podría considerar que la media de la muestra sigue una distribución normal.

**Variable _Fare_**

```{r echo=FALSE, fig.height=3.5, fig.width=7}
par(mfrow = c(1, 2))
{{qqnorm(titanic$Fare, main="Normal Q-Q Plot Fare")
qqline(titanic$Fare)}
  {(hist(titanic$Fare, main='Density histogram Fare', ylab='Density', xlab="Fare", freq=FALSE, breaks=20))
lines(density(titanic$Fare), col="red", lwd=2)}}
```

```{r}
shapiro.test(titanic$Fare)
```

Para la variable _Fare_, los datos se disparan a partir del cuantil teórico 1 y la mayor parte de precios se encuentra entre 0 y 20 dólares. La densidad decrece a medida que aumenta el precio del billete. Además, el p-valor en la prueba es muy inferior a 0.05. Por tanto, los datos no se distribuyen normalemnte, pero al aplicar el TLC, la media de los datos sí sigue una distribución normal.


### Homocedasticidad

Un test de homocedasticidad comprueba la igualdad de varianzas entre los grupos a comparar. Según los gráficos y el test de Shapiro-Wilk, las variables _Age_ y _Fare_ no siguen una distribución normal. Por tanto se utiliza el test de Fligner-Killeen para comprobar la homocedasticidad. Con la misma premisa que para la normalidad, la hipótesis nula asume igualdad de varianzas. Se rechazará si el p-valor es inferior al nivel de significancia $\alpha=0.05$.

**Variable _Age_**

```{r}
fligner.test(Age ~ Survived, data=titanic)
```

El p-valor = 0.04703 < 0.05. Se rechaza la hipótesis nula, pero no de una manera clara. A pesar de aproximarse a 0.05, se concluye que la variable _Age_ presenta varianzas estadísticamente diferentes para los dos grupos de _Survived_.

Esto se puede representar con los boxplots visualizados en el apartado 4.1. La amplitud de la caja y de los bigotes del grupo que no sobrevivió es un poco mayor a la amplitud del grupo que sobrevivió. Esta diferencia pequeña asume la no igualdad de varianzas para las dos distribuciones.

**Variable _Fare_**

```{r}
fligner.test(Fare ~ Survived, data=titanic)
```

Con la variable _Fare_ hay heterocedasticidad: como el p-valor < 0.05, se rechaza la hipótesis nula y se concluye que la variable _Fare_ presenta varianzas estadísticamente diferentes para los dos grupos de _Survived_. Además, en el gráfico `Box plot Survived vs Fare`, la amplitud de la caja y de los bigotes del grupo que sobrevivió es aproximadamente 65 dólares mayor a la amplitud del grupo de no sobrevivió.


## Aplicación de pruebas estadísticas

Todas las pruebas estadísticas tendrán en cuenta la variable objetivo _Survived_. En primer lugar se realizarán dos contrastes de hipótesis, uno con la variable cuantitativa _Fare_ y otro con la variable categórica _Sex_. Luego, una regresión logística y, finalmente, un modelo supervisado _random forest_.

### Contrastes de hipótesis

El primer paso para un contraste de hipótesis es formular la pregunta de investigación. En base a ella se examinará la hipótesis nula y la alternativa. Finalmente, al usar el test estadístico correcto se aceptará o se rechazará la hipótesis con cierto nivel de confianza.

La primera pregunta que nos hacemos es:

**¿Los pasajeros que sobrevivieron pagaron una entrada más cara que los que fallecieron?**

Se plantea si el precio medio del ticket de los supervivientes ($\mu_1$) es mayor al precio medio del ticket de los fallecidos ($\mu_2$). La hipótesis nula ($H_0$) representa el caso donde no hay efecto, es decir, cuando la media de *Fare* es la misma con un nivel de confianza para todos los pasajeros. La hipótesis alternativa ($H_1$) es cuando se responde afirmativamente a la pregunta, es decir, los supervivientes pagaron más que los fallecidos.

$$
H_0: \mu_1 = \mu_2
$$
$$
H_1: \mu_1 > \mu_2
$$

Se trata de un contraste paramétrico unilateral por la derecha de dos muestras independientes (supervivientes y no supervivientes) sobre la media con varianza desconocida.

Al preguntarse si un grupo pagó más que el otro, el test es unilateral por la derecha y, por lo tanto, la zona de aceptación de la $H_0$ está comprendida entre $(-\infty, z_{1-\infty}]$ = $(-\infty, 1.64]$.

El test a utilizar es paramétrico ya que, aunque la igualdad de varianzas no se cumple, por el TLC la distribución de la media de _Fare_ se aproxima a una normal. Así que se realiza el test _t-Student_ con un nivel de confianza del 95%. Se implementa en R mediante la función _t.test()_. Si el p-valor es inferior al nivel de significancia, $H_0$ se rechaza.

```{r}
t.test(titanic$Fare[titanic$Survived=="Yes"], titanic$Fare[titanic$Survived=="No"],
       alternative="greater", var.equal=FALSE)
```

El estadístico de contraste t = 6.7597 cae fuera de la zona de aceptación de la hipótesis nula, y el p-valor = 2.241e-11 < 0.05. Así que se concluye que los pasajeros que sobrevivieron pagaron una entrada más cara que los pasajeros que fallecieron con un nivel de confianza del 95%.


La segunda pregunta que nos hacemos es:

**¿Existe una relación entre el sexo del pasajero y si sobrevivieron o no?**

En este caso, las dos variables a comparar son categóricas, de manera que se aplica el test de $\chi^{2}$ mediante la función *chisq.test()* de R.

Las hipótesis nula y alternativa son:

+ $H_0$: las variables _Sex_ y _Survived_ son independientes.
+ $H_1$: existe una relación entre ambas variables y las diferencias son significativas.

Si el p-valor es inferior al nivel de significancia 0.05, $H_0$ se rechaza.

```{r}
table_survived_sex <- table(titanic$Survived, titanic$Sex)
chisq.test(table_survived_sex)
```

El p-valor es muy inferior al nivel de significancia y, por lo tanto, sí existe una relación de dependencia entre las dos variables con un nivel de confianza del 95%.


### Regresión logística

La regresión logística es un análisis utilizado para predecir el resultado de una variable dicotómica dependiente, en este caso _Survived_, en función de otras variables predictoras.

Primero se divide el conjunto de datos en el subconjunto de entrenamiento o _training_ y el de test o _testing_ mediante el método de exclusión o _holdout_ estratificado. El 75% de los datos totales se usarán para entrenar el modelo y el 25% restante para evaluarlo. Además se usa el método de validación cruzada o _cross-validation_ de tipo *10-fold* para garantizar la independencia de los resultados respecto a la partición.

La regresión logística se implementa mediante el método "glm" en _train_. En un principio incluimos las 7 variables independientes (todas menos _Survived_ que es la variable dependiente), pero se observa que para _Parch_, _Fare_ y _Embarked_ el p-valor era superior a 0.05, es decir, eran variables no significativas. Por tanto se descartaron del modelo y se dejó el actual.

```{r echo=FALSE, warning=FALSE, message=FALSE}
if(!require("rminer")) install.packages("rminer")
library("rminer")
if(!require("caret")) install.packages("caret")
library("caret")
if(!require("pROC")) install.packages("pROC")
library("pROC")
if(!require("randomForest")) install.packages("randomForest")
library("randomForest")
```

```{r}
# Semilla para que los datos sean reproducibles
set.seed(666)

# Separación en train y test
data_glm <- titanic[,c(1:5)]
h<-holdout(data_glm$Survived,ratio=0.75,mode="stratified")
data_train<-data_glm[h$tr,]
data_test<-data_glm[h$ts,]

table(data_train$Survived)
table(data_test$Survived)
```

Las dos clases se han dividido correctamente según el ratio especificado.

```{r}
train_control<- trainControl(method="cv", number=10)
model<-train(Survived~., data=data_train, method="glm", trControl = train_control)
summary(model)
```

Gracias a la eliminación de algunas variables, el criterio de información de Akaike (AIC) ha disminuido hasta 588.53 y todas las variables son significativas. Quienes más contribución tienen en la predicción según los estimadores son los hombres, los pasajeros de tercera clase y la combinación de mujeres de primera clase (Intercept).

Si la probabilidad de la predicción es inferior a 0.5, el pasajero será clasificado como fallecido (clase positiva). En caso contrario como superviviente. Mediante la función _confusionMatrix_ obtenemos la matriz de confusión y las principales métricas.

```{r}
pred <- predict(model, newdata=data_test)
confusionMatrix(pred,data_test$Survived,positive="No")
```

Las métricas obtenidas de la matriz de confusión son buenas, en especial la sensibilidad = 79.56% que corresponde a los pasajeros que el modelo ha clasificado como que no sobrevivieron respecto al total de pasajeros que no sobrevivieron.

Ahora mostramos la curva ROC (*receiver operating characteristic*) que relaciona la sensibilidad con la tasa de falsos positivos.

```{r echo=FALSE, message=FALSE, fig.height=3, fig.width=4.5, fig.align='center'}
prob=predict(model, data_test, type="prob", positive="No")
roc_curve=roc(data_test$Survived, prob$No, data=data_test)

plot(roc_curve)
```

```{r}
auc(roc_curve)
```

Como el área bajo la curva es de 0.8559, cercana a 1, el modelo es preciso y con gran valor de diagnóstico. Tiene gran capacidad de clasificar correctamente si un pasajero sobrevive o no, dado el género, la clase del billete, la edad y el número de hermanos y parejas también en el barco.


### Random Forest

Un Random Forest es un conjunto o _ensamble_ de árboles de decisión combinados con _bagging_. Es decir, en cada árbol se utiliza una porción de los datos de entrenamiento y ningún árbol mira exactamente los mismos datos que otro árbol, compensando los errores de cada uno. Esta capacidad de entrenarse permite al modelo generalizar mejor y evitar el sobreajuste.

Como sucedía con la regresión logística, habíamos probado un modelo inicial con todas las variables pero se descartaron aquellas con una importancia inferior a 20, dejando dentro _Sex_, _Pclass_, _Age_ y _Fare_.

Random Forest es implementa mediante el método "rf" en _train_.

```{r}
set.seed(666)

data_rf <- titanic[,c(1:4,7)]
h<-holdout(data_rf$Survived,ratio=0.75,mode="stratified")
data_train<-data_rf[h$tr,]
data_test<-data_rf[h$ts,]

table(data_train$Survived)
table(data_test$Survived)
```

```{r}
train_control<- trainControl(method="cv", number=10)
model2<-train(Survived~., data=data_train,  method="rf", trControl = train_control)
model2$finalModel
```

La tasa de error durante el entrenamiento es del 15.44%, concretamente el 8.00% para los no supervivientes y el 27.45% para los supervivientes.

El primero de los tres gráficos siguientes muestra el error de la clase `No` (rojo), de la clase `Yes` (verde) y las muestras a usar (negro) sobre la cantidad de los árboles. El segundo muestra el número de nodos usados en los árboles de decisión. Y el segundo la importancia de las variables en el _random forest_.

```{r echo=FALSE, message= FALSE, warning=FALSE}
par(mfrow = c(2, 2))
{plot(model2$finalModel)
hist(treesize(model2$finalModel),
     main = "Número de nodos para los árboles",
     col = "lightblue")
varImpPlot(model2$finalModel,
           n.var = 5,
           main = "Importancia de las variables")}
```

La evaluación del modelo queda de la siguiente manera:
```{r}
pred <- predict(model2, newdata=data_test)
confusionMatrix(pred,data_test$Survived,positive="No")
```

Este modelo obtiene una _accuracy_ del 83.33% y una sensibilidad del 86.13%, unas métricas superiores a las obtenidas con el modelo de regresión logística.

```{r echo=FALSE, message=FALSE, fig.height=3, fig.width=4.5, fig.align='center'}
prob=predict(model2, data_test, type="prob", positive="No")
roc_curve=roc(data_test$Survived, prob$No, data=data_test)

plot(roc_curve)
```

```{r}
auc(roc_curve)
```

El modelo de _randomforest_ tiene gran capacidad de clasificar correctamente si un pasajero sobrevive o no, dado el género, la clase del billete, la edad y el precio del billete.



# Resolución del problema

A largo del análisis hemos ido conociendo más el dataset y sacando conclusiones que resumiremos a continuación.

Durante la selección de datos logramos entender que representaban cada una de las columnas y así poder descartar aquellas que no iban a aportar ningún valor en el análisis posterior.

Más adelante relaizamos la limpieza de los datos donde realizamos la detección de outliers en las variables continuas y concluimos que estos outliers no eran errores que tuviéramos que descartar o modificar.

En la parte fundamental de la práctica, el análisis de datos, tomamos la variable _Survived_ como la variable objetivo y sobre la que vamos a centrar nuestro análisis. Con un primer análsis visual observamos que variables como _Sex_ o _Fare_ si tienen una clara influencia a la hora de discernir si un pasajero sobrevivió o no.

Estudiamos también las variables continuas y concluimos que no siguen distribuciones normales por lo que en los tests de homocedasticidad no debemos suponer normalidad. Después de realizar estos tests concluimos que para _Age_ sí hay igualdad de varianzas en los conjuntos de supervivientes y no supervivientes, pero no con _Fare_.

En los contrastes de hipótesis comprobamos que los supervivientes pagaron billetes más caros y que existe una relación entre las variables _Sex_ y _Survived_ como habíamos visto en el análisis visual.

Finalmente decidimos aplicar dos modelos de aprendizaje automático para determinar la importancia de las variables y obtenemos conclusiones al resto de los análisis donde vemos que las variables _Age_, _Pclass_, _Sex_ y _Fare_ son las variables más importantes. Con modelo de Random Forest hemos obtenido mejores métricas que con la regresión logística.

Tras todas estas conclusiones podemos decir que hemos conseguido responder al problema ya que hemos obtenido bastante información sobre qué criterios se siguieron a la hora de intentar salvar a los pasajeros y además hemos construido modelos capaces de predecir si un pasajero sobrevivió o no.


# Contribuciones al trabajo

|Contribuciones|Firma|
|--------------|-----|
|Investigación previa|Jorge SV y Álvaro LC|
|Redacción de las respuestas|Jorge SV y Álvaro LC|
|Desarrollo del código|Jorge SV y Álvaro LC|




